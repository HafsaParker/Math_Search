# -*- coding: utf-8 -*-
"""Copy of LaTeX-OCR training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VVFQb5PQXTaKH8lGI2YIxhn-icviz7Ma

# Train a LaTeX OCR model
In this brief notebook I show how you can finetune/train an OCR model.

I've opted to mix in handwritten data into the regular pdf LaTeX images. For that I started out with the released pretrained model and continued training on the slightly larger corpus.
"""

#!git clone https://github.com/lukas-blecher/LaTeX-OCR.git

import os
os.chdir('LaTeX-OCR')

#!pip install -r requirements.txt -q
#!pip install gpustat -q
#!pip install opencv-python-headless==4.1.2.30 -U -q

# check what GPU we have
#!gpustat

# download pretrained model
#!curl -L -o checkpoints/weights.pth https://github.com/lukas-blecher/LaTeX-OCR/releases/download/v0.0.1/weights.pth

# Google Drive ids
# handwritten: 13vjxGYrFCuYnwgDIUqkxsNGKk__D_sOM
# pdf - images: 176PKaCUDWmTJdQwc-OfkO0y8t4gLsIvQ
# pdf - math: 1QUjX6PFWPa-HBWdcY-7bA5TRVUnbyS1D
#!gdown -O dataset/data/crohme.zip --id 13vjxGYrFCuYnwgDIUqkxsNGKk__D_sOM
os.chdir('dataset/data')
#!unzip -q crohme.zip
# split handwritten data into val set and train set
os.chdir('images')
#!mkdir ../valimages
#!ls | shuf -n 1000 | xargs -i mv {} ../valimages
os.chdir('../../..')

"""Now we generate the datasets. We can string multiple datasets together to get one large lookup table. The only thing saved in these pkl files are image sizes, image location and the ground truth latex code. That way we can serve batches of images with the same dimensionality."""

#!python dataset/dataset.py -i dataset/data/images -e dataset/data/CROHME_math.txt -t dataset/tokenizer.json -o dataset/data/train.pkl

#!python dataset/dataset.py -i dataset/data/valimages -e dataset/data/CROHME_math.txt -t dataset/tokenizer.json -o dataset/data/val.pkl

# If using wandb
#!pip install -q wandb 
#!wandb login

# generate colab specific config (set 'debug' to true if wandb is not used)
#!echo {backbone_layers: [2, 3, 7], betas: [0.9, 0.999], batchsize: 10, bos_token: 1, channels: 1, data: dataset/data/train.pkl, debug: false, decoder_args: {'attn_on_attn': true, 'cross_attend': true, 'ff_glu': true, 'rel_pos_bias': false, 'use_scalenorm': false}, dim: 256, encoder_depth: 4, eos_token: 2, epochs: 1, gamma: 0.9995, heads: 8, id: null, load_chkpt: 'checkpoints/weights.pth', lr: 0.001, lr_step: 30, max_height: 192, max_seq_len: 512, max_width: 672, min_height: 32, min_width: 32, model_path: checkpoints, name: mixed, num_layers: 4, num_tokens: 8000, optimizer: Adam, output_path: outputs, pad: false, pad_token: 0, patch_size: 16, sample_freq: 2000, save_freq: 1, scheduler: StepLR, seed: 42, temperature: 0.2, test_samples: 5, testbatchsize: 20, tokenizer: dataset/tokenizer.json, valbatches: 100, valdata: dataset/data/val.pkl} > settings/colab.yaml

#!python train.py --config settings/colab.yaml

#!python eval.py -c checkpoints/mixed/mixed_e01.pth --config settings/colab.yaml -d dataset/data/val.pkl

#!python eval.py -c checkpoints/mixed/mixed_e01.pth --config settings/colab.yaml -d dataset/data/train.pkl

# Commented out IPython magic to ensure Python compatibility.
#@title  { run: "auto", vertical-output: true, display-mode: "code" }
# %reload_ext autoreload
# %autoreload
import PIL
#!pip install Pillow -U -qq
if int(PIL.__version__[0]) < 9:
    print('Mandatory restart: Execute this cell again!')
    import os
    os.kill(os.getpid(), 9)
import os
os.chdir('/content/LaTeX-OCR')
#!pip install -r requirements.txt -qq
#!pip install opencv-python-headless==4.1.2.30 -U -qq

#!curl -L -s -o checkpoints/mixed/mixed_e14.pth /content/LaTeX-OCR/checkpoints/mixed/mixed_e01.pth
#!curl -L -s -o checkpoints/image_resizer.pth https://github.com/lukas-blecher/LaTeX-OCR/releases/download/v0.0.1/image_resizer.pth

def upload_files():
  from google.colab import files
  from io import BytesIO
  uploaded = files.upload()
  return [(name, BytesIO(b)) for name, b in uploaded.items()]

import pix2tex
from PIL import Image
args = pix2tex.initialize()

from IPython.display import HTML, Math
display(HTML("<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/"
             "latest.js?config=default'></script>"))
table = r'\begin{array} {l|l} %s  \end{array}'

imgs = upload_files()
predictions = []
for name, f in imgs:
    img = Image.open(f)
    math = pix2tex.call_model(*args, img)
    print(math)
    predictions.append('\\mathrm{%s} & \\displaystyle{%s}'%(name, math))
Math(table%'\\\\'.join(predictions))

from google.colab import drive
drive.mount('/content/drive')

#!zip -r /content/file.zip /content/LaTeX-OCR

#!python pix2tex.py --checkpoint checkpoints/mixed/mixed_e01.pth

#!zip -r /content/file.zip /content/LaTeX-OCR